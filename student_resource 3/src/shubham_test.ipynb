{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b70b34e",
   "metadata": {},
   "source": [
    "### Basic library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719d15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911e33",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3136aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebd689",
   "metadata": {},
   "source": [
    "### Run Sanity check using src/sanity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bb3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing successfull for file: ../dataset/sample_test_out.csv\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa79459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid unit [lbs] found in 6.75 lbs. Allowed units: {'cubic foot', 'cup', 'cubic inch', 'kilogram', 'foot', 'centimetre', 'kilowatt', 'centilitre', 'milligram', 'decilitre', 'gallon', 'ounce', 'yard', 'litre', 'metre', 'kilovolt', 'volt', 'pint', 'inch', 'microgram', 'microlitre', 'quart', 'imperial gallon', 'ton', 'millivolt', 'watt', 'millimetre', 'pound', 'millilitre', 'gram', 'fluid ounce'}\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out_fail.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe930a8",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d1aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:10<00:00,  8.42it/s]\n",
      "  1%|          | 1538/263859 [03:08<8:54:55,  8.17it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_images\n\u001b[1;32m      2\u001b[0m download_images(sample_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_link\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../images\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdownload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../images\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/7th Sem/Amazon ML/student_resource 3/src/utils.py:77\u001b[0m, in \u001b[0;36mdownload_images\u001b[0;34m(image_links, download_folder, allow_multiprocessing)\u001b[0m\n\u001b[1;32m     73\u001b[0m download_image_partial \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m     74\u001b[0m     download_image, save_folder\u001b[38;5;241m=\u001b[39mdownload_folder, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m64\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_image_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_links\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_links\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     79\u001b[0m     pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/Downloads/7th Sem/Amazon ML/shubham/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import download_images\n",
    "download_images(sample_test['image_link'], '../images')\n",
    "download_images(train['image_link'], '../images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89aaba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(os.listdir('../images')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ba3d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ../images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a302b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "test_df = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c38a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calabrian Powder  Ca-ean Chili\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    result = reader.readtext(image_path)\n",
    "    text = \" \".join([res[1] for res in result])\n",
    "    return text\n",
    "\n",
    "# Sample image link\n",
    "link = train_df.head()['image_link'][1]\n",
    "images_1 = Path(link).name\n",
    "\n",
    "# Adjust the path to the directory where images are stored\n",
    "sample_image_path = f\"../images/41ADVPQgZOL.jpg\"\n",
    "\n",
    "# Debugging: Check if the file exists\n",
    "if os.path.exists(sample_image_path):\n",
    "    extracted_text = extract_text_from_image(sample_image_path)\n",
    "    print(extracted_text)\n",
    "else:\n",
    "    print(f\"File not found: {sample_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676db3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction with CNN\n",
    "# main.py\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load a pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.eval()\n",
    "\n",
    "# Image preprocessing function\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet(image)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# Example usage\n",
    "image_features = extract_image_features(sample_image_path)\n",
    "# print(\"\\n\")\n",
    "# print(image_features)\n",
    "# print(\"\\n\")\n",
    "print(image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c3e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Data Processing\n",
    "import re\n",
    "\n",
    "def extract_entity_value(extracted_text):\n",
    "    # Simple regex pattern to extract \"number unit\" format\n",
    "    pattern = r'(\\d+(\\.\\d+)?)\\s*(gram|kilogram|centimetre|inch|ounce)'\n",
    "    match = re.search(pattern, extracted_text)\n",
    "    if match:\n",
    "        return f\"{match.group(1)} {match.group(3)}\"\n",
    "    return \"\"\n",
    "\n",
    "# Example usage\n",
    "entity_value = extract_entity_value(extracted_text)\n",
    "print(entity_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3575e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_link', 'group_id', 'entity_name', 'entity_value'], dtype='object')\n",
      "Index(['index', 'image_link', 'group_id', 'entity_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Checking Columns\n",
    "print(train_df.columns)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87079f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110EibNyclL.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print(train_df.head())\n",
    "\n",
    "link=test_df.head()['image_link'][0]\n",
    "Path(link).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1477131",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/shubham/Downloads/7th Sem/Amazon ML/student_resource 3/images/0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Prepare training data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Extract image features using the DataFrame's own index for training data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m X_image_features \u001b[38;5;241m=\u001b[39m [\u001b[43mextract_image_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../images/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m train_df\u001b[38;5;241m.\u001b[39mindex]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Extract text features for training data\u001b[39;00m\n\u001b[1;32m     13\u001b[0m X_text_features \u001b[38;5;241m=\u001b[39m [extract_text_from_image(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m train_df\u001b[38;5;241m.\u001b[39mindex]\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mextract_image_features\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_image_features\u001b[39m(image_path):\n\u001b[0;32m---> 19\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     image \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Downloads/7th Sem/Amazon ML/shubham/lib/python3.12/site-packages/PIL/Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/shubham/Downloads/7th Sem/Amazon ML/student_resource 3/images/0.jpg'"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Prepare training data\n",
    "# Extract image features using the DataFrame's own index for training data\n",
    "X_image_features = [extract_image_features(f'../images/{idx}.jpg') for idx in train_df.index]\n",
    "\n",
    "# Extract text features for training data\n",
    "X_text_features = [extract_text_from_image(f'../images/{idx}.jpg') for idx in train_df.index]\n",
    "\n",
    "# Assuming 'test_df' is your DataFrame for the test set\n",
    "# Extract image features using the 'index' column for test data\n",
    "X_test_image_features = [extract_image_features(f'../images/{idx}.jpg') for idx in test_df['index']]\n",
    "\n",
    "# Extract text features for test data\n",
    "X_test_text_features = [extract_text_from_image(f'../images/{idx}.jpg') for idx in test_df['index']]\n",
    "\n",
    "# Encode the target variable\n",
    "y = train_df['entity_value']\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train_img, X_test_img, X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_image_features, X_text_features, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine image and text features in a pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model using image features only for simplicity\n",
    "model_pipeline.fit(X_train_text, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Training accuracy: {model_pipeline.score(X_test_text, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shubham",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
